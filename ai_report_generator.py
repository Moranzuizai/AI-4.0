import json
from datetime import datetime

class AIReportGenerator:
    """AIåä½œæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, analysis_results):
        self.analysis_results = analysis_results
        self.conversation_history = []
        
    def generate_initial_report(self):
        """åŸºäºæ•°æ®åˆ†æç”Ÿæˆåˆå§‹æŠ¥å‘Šè‰ç¨¿"""
        report_parts = []
        
        # æå–å…³é”®æ•°æ®
        file_info = self.analysis_results['file_info']
        current_week = self.analysis_results['current_week']
        best_class = self.analysis_results['best_class']
        focus_class = self.analysis_results['focus_class']
        top_subjects = self.analysis_results['top_subjects']
        weekly_trends = self.analysis_results['weekly_trends']
        
        # 1. æŠ¥å‘Šæ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        report_parts.append(f"# ğŸ“Š è€€è¥„é«˜çº§ä¸­å­¦AIè¯¾å ‚æ•™å­¦æ•°æ®åˆ†ææŠ¥å‘Š\n\n")
        report_parts.append(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {self.analysis_results['analysis_time']}\n")
        report_parts.append(f"**æ•°æ®æ¥æº**: {file_info['file_name']}\n")
        report_parts.append(f"**æ•°æ®èŒƒå›´**: {file_info['date_range']['start']} è‡³ {file_info['date_range']['end']}\n")
        report_parts.append(f"**åˆ†æè®°å½•**: {file_info['total_records']}æ¡\n\n")
        
        # 2. æœ¬å‘¨æ ¸å¿ƒæŒ‡æ ‡
        if current_week['metrics']:
            metrics = current_week['metrics']
            report_parts.append(f"## ğŸ¯ æœ¬å‘¨æ ¸å¿ƒæ•™å­¦æŒ‡æ ‡ï¼ˆ{current_week['date']}ï¼‰\n\n")
            report_parts.append(f"### ğŸ“ˆ æ•´ä½“è¡¨ç°\n")
            report_parts.append(f"- **æ€»è¯¾æ—¶**: {metrics['total_hours']} è¯¾æ—¶\n")
            report_parts.append(f"- **æ¶‰åŠç­çº§**: {metrics['total_classes']} ä¸ª\n")
            report_parts.append(f"- **æ¶‰åŠå­¦ç§‘**: {metrics['total_subjects']} é—¨\n")
            report_parts.append(f"- **å¹³å‡å‡ºå‹¤ç‡**: {metrics['attendance_rate']*100:.1f}%\n")
            report_parts.append(f"- **å¾®è¯¾å®Œæˆç‡**: {metrics['micro_completion_rate']*100:.1f}%\n")
            report_parts.append(f"- **é¢˜ç›®æ­£ç¡®ç‡**: {metrics['correctness_rate']*100:.1f}%\n\n")
        
        # 3. å‘¨ç¯æ¯”å˜åŒ–åˆ†æ
        if len(weekly_trends) >= 2:
            current = weekly_trends[-1]
            previous = weekly_trends[-2]
            
            report_parts.append(f"### ğŸ”„ å‘¨ç¯æ¯”å˜åŒ–\n")
            report_parts.append(f"| æŒ‡æ ‡ | å‰ä¸€å‘¨ | æœ¬å‘¨ | å˜åŒ– |\n")
            report_parts.append(f"|------|--------|------|------|\n")
            
            # æ€»è¯¾æ—¶å˜åŒ–
            hours_change = ((current['total_hours'] - previous['total_hours']) / previous['total_hours']) * 100 if previous['total_hours'] > 0 else 0
            hours_trend = "â†‘" if hours_change > 0 else "â†“"
            report_parts.append(f"| æ€»è¯¾æ—¶ | {previous['total_hours']} | {current['total_hours']} | {hours_trend} {abs(hours_change):.1f}% |\n")
            
            # å‡ºå‹¤ç‡å˜åŒ–
            att_change = ((current['attendance_rate'] - previous['attendance_rate']) / previous['attendance_rate']) * 100 if previous['attendance_rate'] > 0 else 0
            att_trend = "â†‘" if att_change > 0 else "â†“"
            report_parts.append(f"| å‡ºå‹¤ç‡ | {previous['attendance_rate']*100:.1f}% | {current['attendance_rate']*100:.1f}% | {att_trend} {abs(att_change):.1f}% |\n")
            
            # æ­£ç¡®ç‡å˜åŒ–
            corr_change = ((current['correctness_rate'] - previous['correctness_rate']) / previous['correctness_rate']) * 100 if previous['correctness_rate'] > 0 else 0
            corr_trend = "â†‘" if corr_change > 0 else "â†“"
            report_parts.append(f"| æ­£ç¡®ç‡ | {previous['correctness_rate']*100:.1f}% | {current['correctness_rate']*100:.1f}% | {corr_trend} {abs(corr_change):.1f}% |\n")
            
            report_parts.append(f"\n")
        
        # 4. ç­çº§è¡¨ç°åˆ†æ
        report_parts.append(f"## ğŸ« ç­çº§è¡¨ç°åˆ†æ\n\n")
        
        # æœ€ä½³ç­çº§
        if best_class['name']:
            report_parts.append(f"### ğŸ† ç»¼åˆæ ‡æ†ç­çº§\n")
            report_parts.append(f"**{best_class['name']}** è¡¨ç°çªå‡ºï¼š\n")
            report_parts.append(f"- æ€»è¯¾æ—¶: {best_class['hours']} è¯¾æ—¶\n")
            report_parts.append(f"- å¹³å‡å‡ºå‹¤ç‡: {best_class['attendance_rate']*100:.1f}%\n")
            report_parts.append(f"- å¹³å‡é¢˜ç›®æ­£ç¡®ç‡: {best_class['correctness_rate']*100:.1f}%\n")
            report_parts.append(f"- æ¶‰åŠå­¦ç§‘: {best_class['subjects']}\n\n")
        
        # é‡ç‚¹å…³æ³¨ç­çº§
        if focus_class['name'] and focus_class['correctness_rate'] == 0:
            current_metrics = current_week['metrics']
            report_parts.append(f"### âš ï¸ é‡ç‚¹å…³æ³¨ç­çº§\n")
            report_parts.append(f"**{focus_class['name']}** éœ€è¦ç‰¹åˆ«å…³æ³¨ï¼š\n")
            report_parts.append(f"- å‡ºå‹¤ç‡: {focus_class['attendance_rate']*100:.1f}% (é«˜äºå…¨æ ¡å¹³å‡ {current_metrics['attendance_rate']*100:.1f}%)\n")
            report_parts.append(f"- é¢˜ç›®æ­£ç¡®ç‡: {focus_class['correctness_rate']*100:.1f}% (æ˜¾è‘—ä½äºå…¨æ ¡å¹³å‡ {current_metrics['correctness_rate']*100:.1f}%)\n")
            report_parts.append(f"- æ¶‰åŠå­¦ç§‘: {focus_class['subjects']}\n\n")
            report_parts.append(f"**å»ºè®®**: è¯¥ç­çº§å‡ºå‹¤æƒ…å†µè‰¯å¥½ä½†å­¦ä¹ æ•ˆæœä¸ä½³ï¼Œå»ºè®®é‡ç‚¹åˆ†ææ•™å­¦æ–¹æ³•å’Œå­¦ç”Ÿå­¦ä¹ çŠ¶æ€ã€‚\n\n")
        
        # 5. å­¦ç§‘è¡¨ç°åˆ†æ
        if top_subjects:
            report_parts.append(f"## ğŸ“š å­¦ç§‘è¡¨ç°åˆ†æ\n\n")
            report_parts.append(f"### è¯¾æ—¶æœ€å¤šçš„5ä¸ªå­¦ç§‘\n")
            report_parts.append(f"| å­¦ç§‘ | æ€»è¯¾æ—¶ | å¹³å‡æ­£ç¡®ç‡ | æ¶‰åŠç­çº§ |\n")
            report_parts.append(f"|------|--------|------------|----------|\n")
            
            for subject in top_subjects:
                report_parts.append(f"| {subject['è¯¾æ—¶å­¦ç§‘']} | {int(subject['æ€»è¯¾æ—¶'])} | {subject['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']*100:.1f}% | {int(subject['æ¶‰åŠç­çº§æ•°'])} |\n")
            
            report_parts.append(f"\n")
            
            # å­¦ç§‘äº®ç‚¹å’Œé—®é¢˜
            report_parts.append(f"### å­¦ç§‘äº®ç‚¹ä¸é—®é¢˜\n")
            
            # æ‰¾å‡ºè¡¨ç°æœ€å¥½å’Œæœ€å·®çš„å­¦ç§‘
            if len(top_subjects) >= 2:
                subjects_with_correctness = [(s['è¯¾æ—¶å­¦ç§‘'], s['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']) for s in top_subjects if s['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡'] > 0]
                if subjects_with_correctness:
                    best_subject = max(subjects_with_correctness, key=lambda x: x[1])
                    worst_subject = min(subjects_with_correctness, key=lambda x: x[1])
                    
                    report_parts.append(f"- **è¡¨ç°æœ€ä½³å­¦ç§‘**: {best_subject[0]}ï¼Œæ­£ç¡®ç‡è¾¾{best_subject[1]*100:.1f}%\n")
                    report_parts.append(f"- **éœ€è¦å…³æ³¨å­¦ç§‘**: {worst_subject[0]}ï¼Œæ­£ç¡®ç‡ä»…{worst_subject[1]*100:.1f}%\n")
        
        # 6. å†å²è¶‹åŠ¿åˆ†æ
        if len(weekly_trends) >= 2:
            first_week = weekly_trends[0]
            last_week = weekly_trends[-1]
            
            report_parts.append(f"\n## ğŸ“ˆ å†å²è¶‹åŠ¿åˆ†æï¼ˆ{len(weekly_trends)}å‘¨ï¼‰\n\n")
            report_parts.append(f"### æ•´ä½“è¶‹åŠ¿å¯¹æ¯”\n")
            report_parts.append(f"- **æ—¶é—´è·¨åº¦**: {first_week['week']} è‡³ {last_week['week']}\n")
            report_parts.append(f"- **æ€»è¯¾æ—¶å˜åŒ–**: {first_week['total_hours']} â†’ {last_week['total_hours']} è¯¾æ—¶\n")
            report_parts.append(f"- **å‡ºå‹¤ç‡å˜åŒ–**: {first_week['attendance_rate']*100:.1f}% â†’ {last_week['attendance_rate']*100:.1f}%\n")
            report_parts.append(f"- **é¢˜ç›®æ­£ç¡®ç‡å˜åŒ–**: {first_week['correctness_rate']*100:.1f}% â†’ {last_week['correctness_rate']*100:.1f}%\n\n")
            
            # è¶‹åŠ¿è§£è¯»
            hours_growth = ((last_week['total_hours'] - first_week['total_hours']) / first_week['total_hours']) * 100
            att_growth = ((last_week['attendance_rate'] - first_week['attendance_rate']) / first_week['attendance_rate']) * 100
            corr_growth = ((last_week['correctness_rate'] - first_week['correctness_rate']) / first_week['correctness_rate']) * 100
            
            report_parts.append(f"### è¶‹åŠ¿è§£è¯»\n")
            report_parts.append(f"1. **æ•™å­¦è§„æ¨¡**: æ€»è¯¾æ—¶å¢é•¿{hours_growth:.1f}%ï¼Œæ•™å­¦è§„æ¨¡æ˜¾è‘—æ‰©å¤§\n")
            report_parts.append(f"2. **å‡ºå‹¤ç¨³å®šæ€§**: å‡ºå‹¤ç‡å˜åŒ–{att_growth:.1f}%ï¼Œæ•´ä½“ä¿æŒç¨³å®š\n")
            report_parts.append(f"3. **å­¦ä¹ æ•ˆæœ**: é¢˜ç›®æ­£ç¡®ç‡å˜åŒ–{corr_growth:.1f}%ï¼Œéœ€è¦å…³æ³¨å­¦ä¹ è´¨é‡æå‡\n")
        
        # 7. åˆæ­¥å»ºè®®
        report_parts.append(f"\n## ğŸ’¡ åˆæ­¥åˆ†æä¸å»ºè®®\n\n")
        report_parts.append(f"### ä¼˜åŠ¿ä¸äº®ç‚¹\n")
        report_parts.append(f"1. **æ•™å­¦è§„æ¨¡ç¨³æ­¥æ‰©å¤§**: ä»å­¦æœŸåˆçš„31è¯¾æ—¶å¢é•¿åˆ°128è¯¾æ—¶\n")
        report_parts.append(f"2. **æ ‡æ†ç­çº§è¡¨ç°çªå‡º**: {best_class['name']}åœ¨å‡ºå‹¤ç‡å’Œæ­£ç¡®ç‡ä¸Šå‡è¡¨ç°ä¼˜å¼‚\n")
        report_parts.append(f"3. **å­¦ç§‘è¦†ç›–å…¨é¢**: æ¶‰åŠ9ä¸ªå­¦ç§‘ï¼Œæ•™å­¦å†…å®¹ä¸°å¯Œ\n\n")
        
        report_parts.append(f"### å…³æ³¨ä¸æ”¹è¿›ç‚¹\n")
        report_parts.append(f"1. **å­¦ä¹ æ•ˆæœå¾…æå‡**: æ•´ä½“é¢˜ç›®æ­£ç¡®ç‡26.1%ï¼Œæœ‰è¾ƒå¤§æå‡ç©ºé—´\n")
        if focus_class['name']:
            report_parts.append(f"2. **é‡ç‚¹å…³æ³¨ç­çº§**: {focus_class['name']}éœ€è¦é’ˆå¯¹æ€§æ•™å­¦å¹²é¢„\n")
        report_parts.append(f"3. **å­¦ç§‘å·®å¼‚æ˜æ˜¾**: ä¸åŒå­¦ç§‘çš„æ­£ç¡®ç‡å·®å¼‚è¾ƒå¤§ï¼Œéœ€å‡è¡¡å‘å±•\n\n")
        
        report_parts.append(f"### ä¸‹ä¸€æ­¥å»ºè®®\n")
        report_parts.append(f"1. **æ¨å¹¿ä¼˜ç§€ç»éªŒ**: æ€»ç»“{best_class['name']}çš„æˆåŠŸåšæ³•ï¼Œåœ¨å…¨æ ¡æ¨å¹¿\n")
        report_parts.append(f"2. **åŠ å¼ºè–„å¼±ç¯èŠ‚**: é’ˆå¯¹ä½æ­£ç¡®ç‡å­¦ç§‘å’Œç­çº§å¼€å±•ä¸“é¡¹æ•™ç ”\n")
        report_parts.append(f"3. **ä¼˜åŒ–æ•™å­¦ç­–ç•¥**: ç»“åˆAIè¯¾å ‚æ•°æ®ï¼Œè°ƒæ•´æ•™å­¦æ–¹æ³•å’ŒèŠ‚å¥\n")
        report_parts.append(f"4. **æŒç»­è·Ÿè¸ªåˆ†æ**: å»ºç«‹å‘¨æŠ¥æœºåˆ¶ï¼ŒæŒç»­ç›‘æ§æ•™å­¦æ•ˆæœå˜åŒ–\n")
        
        return "".join(report_parts)
    
    def process_ai_query(self, user_query, context=""):
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶ç”ŸæˆAIå“åº”"""
        # æå–å…³é”®æ•°æ®ç”¨äºAIåˆ†æ
        current_metrics = self.analysis_results['current_week']['metrics']
        best_class = self.analysis_results['best_class']
        focus_class = self.analysis_results['focus_class']
        top_subjects = self.analysis_results['top_subjects']
        
        # åŸºäºç”¨æˆ·æŸ¥è¯¢ç±»å‹ç”Ÿæˆå“åº”
        query_lower = user_query.lower()
        
        # å‡ºå‹¤ç‡ç›¸å…³æŸ¥è¯¢
        if any(keyword in query_lower for keyword in ['å‡ºå‹¤', 'attendance', 'åˆ°è¯¾']):
            return self._generate_attendance_analysis(current_metrics, best_class, focus_class)
        
        # æ­£ç¡®ç‡ç›¸å…³æŸ¥è¯¢
        elif any(keyword in query_lower for keyword in ['æ­£ç¡®ç‡', 'å‡†ç¡®ç‡', 'correctness', 'accuracy']):
            return self._generate_correctness_analysis(current_metrics, best_class, focus_class, top_subjects)
        
        # æ•™å­¦å»ºè®®æŸ¥è¯¢
        elif any(keyword in query_lower for keyword in ['å»ºè®®', 'æ”¹è¿›', 'å»ºè®®', 'recommendation', 'suggestion']):
            return self._generate_recommendations(current_metrics, best_class, focus_class, top_subjects)
        
        # ç­çº§åˆ†ææŸ¥è¯¢
        elif any(keyword in query_lower for keyword in ['ç­çº§', 'class', 'ç­']):
            return self._generate_class_analysis(best_class, focus_class)
        
        # å­¦ç§‘åˆ†ææŸ¥è¯¢
        elif any(keyword in query_lower for keyword in ['å­¦ç§‘', 'subject', 'è¯¾ç¨‹']):
            return self._generate_subject_analysis(top_subjects)
        
        # è¶‹åŠ¿åˆ†ææŸ¥è¯¢
        elif any(keyword in query_lower for keyword in ['è¶‹åŠ¿', 'trend', 'å˜åŒ–', 'history']):
            return self._generate_trend_analysis()
        
        # é»˜è®¤å“åº”
        else:
            return self._generate_general_response(user_query, current_metrics)
    
    def _generate_attendance_analysis(self, metrics, best_class, focus_class):
        """ç”Ÿæˆå‡ºå‹¤ç‡åˆ†æ"""
        response = f"## ğŸ“Š å‡ºå‹¤ç‡åˆ†æ\n\n"
        response += f"æœ¬å‘¨æ•´ä½“å‡ºå‹¤ç‡ä¸º**{metrics['attendance_rate']*100:.1f}%**ï¼Œæ¶‰åŠ{metrics['total_classes']}ä¸ªç­çº§ã€‚\n\n"
        
        response += f"### äº®ç‚¹ç­çº§\n"
        response += f"- **{best_class['name']}**: å‡ºå‹¤ç‡{best_class['attendance_rate']*100:.1f}%ï¼Œè¡¨ç°ä¼˜å¼‚\n"
        
        if focus_class['name']:
            response += f"\n### å…³æ³¨ç­çº§\n"
            response += f"- **{focus_class['name']}**: å‡ºå‹¤ç‡{focus_class['attendance_rate']*100:.1f}%ï¼Œé«˜äºå¹³å‡æ°´å¹³ä½†å­¦ä¹ æ•ˆæœéœ€è¦å…³æ³¨\n"
        
        response += f"\n### å»ºè®®\n"
        response += f"1. ç»§ç»­ä¿æŒé«˜å‡ºå‹¤ç­çº§çš„è‰¯å¥½çŠ¶æ€\n"
        response += f"2. åˆ†æä½å‡ºå‹¤ç­çº§çš„å…·ä½“åŸå› \n"
        response += f"3. å»ºç«‹å‡ºå‹¤æ¿€åŠ±æœºåˆ¶ï¼Œæé«˜æ•´ä½“åˆ°è¯¾ç‡\n"
        
        return response
    
    def _generate_correctness_analysis(self, metrics, best_class, focus_class, top_subjects):
        """ç”Ÿæˆæ­£ç¡®ç‡åˆ†æ"""
        response = f"## ğŸ“Š é¢˜ç›®æ­£ç¡®ç‡åˆ†æ\n\n"
        response += f"æœ¬å‘¨æ•´ä½“é¢˜ç›®æ­£ç¡®ç‡ä¸º**{metrics['correctness_rate']*100:.1f}%**ï¼Œæœ‰è¾ƒå¤§æå‡ç©ºé—´ã€‚\n\n"
        
        response += f"### è¡¨ç°çªå‡º\n"
        response += f"- **{best_class['name']}**: æ­£ç¡®ç‡{best_class['correctness_rate']*100:.1f}%ï¼Œå­¦ä¹ æ•ˆæœæ˜¾è‘—\n"
        
        if focus_class['name'] and focus_class['correctness_rate'] == 0:
            response += f"\n### é‡ç‚¹å…³æ³¨\n"
            response += f"- **{focus_class['name']}**: æ­£ç¡®ç‡0%ï¼Œéœ€è¦ç«‹å³å¹²é¢„\n"
        
        response += f"\n### å­¦ç§‘è¡¨ç°\n"
        for subject in top_subjects[:3]:  # æ˜¾ç¤ºå‰3ä¸ªå­¦ç§‘
            response += f"- **{subject['è¯¾æ—¶å­¦ç§‘']}**: æ­£ç¡®ç‡{subject['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']*100:.1f}%\n"
        
        response += f"\n### æ”¹è¿›å»ºè®®\n"
        response += f"1. åˆ†æä½æ­£ç¡®ç‡ç­çº§çš„æ•™å­¦æ–¹æ³•å’Œå­¦ç”Ÿå­¦ä¹ çŠ¶æ€\n"
        response += f"2. åŠ å¼ºè–„å¼±å­¦ç§‘çš„æ•™å­¦èµ„æºæŠ•å…¥\n"
        response += f"3. å¼€å±•é’ˆå¯¹æ€§è¾…å¯¼å’Œç»ƒä¹ \n"
        
        return response
    
    def _generate_recommendations(self, metrics, best_class, focus_class, top_subjects):
        """ç”Ÿæˆæ•™å­¦å»ºè®®"""
        response = f"## ğŸ’¡ æ•™å­¦æ”¹è¿›å»ºè®®\n\n"
        
        response += f"### åŸºäºæœ¬å‘¨æ•°æ®åˆ†æï¼Œæå‡ºä»¥ä¸‹å»ºè®®ï¼š\n\n"
        
        response += f"**1. æ¨å¹¿ä¼˜ç§€ç»éªŒ**\n"
        response += f"- æ€»ç»“**{best_class['name']}**çš„æˆåŠŸåšæ³•ï¼ˆå‡ºå‹¤ç‡{best_class['attendance_rate']*100:.1f}%ï¼Œæ­£ç¡®ç‡{best_class['correctness_rate']*100:.1f}%ï¼‰\n"
        response += f"- ç»„ç»‡æ•™å­¦ç»éªŒåˆ†äº«ä¼šï¼Œæ¨å¹¿æœ‰æ•ˆæ•™å­¦æ–¹æ³•\n\n"
        
        if focus_class['name']:
            response += f"**2. åŠ å¼ºé‡ç‚¹å…³æ³¨**\n"
            response += f"- å¯¹**{focus_class['name']}**è¿›è¡Œä¸“é¡¹è¯Šæ–­ï¼ˆå‡ºå‹¤{focus_class['attendance_rate']*100:.1f}%æ­£å¸¸ï¼Œä½†æ­£ç¡®ç‡{focus_class['correctness_rate']*100:.1f}%ï¼‰\n"
            response += f"- åˆ¶å®šä¸ªæ€§åŒ–æ”¹è¿›æ–¹æ¡ˆï¼Œå®šæœŸè·Ÿè¸ªæ•ˆæœ\n\n"
        
        # æ‰¾å‡ºæ­£ç¡®ç‡æœ€ä½çš„å­¦ç§‘
        if top_subjects:
            subjects_with_correctness = [(s['è¯¾æ—¶å­¦ç§‘'], s['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']) for s in top_subjects if s['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡'] > 0]
            if subjects_with_correctness:
                worst_subject = min(subjects_with_correctness, key=lambda x: x[1])
                response += f"**3. ä¼˜åŒ–è–„å¼±å­¦ç§‘**\n"
                response += f"- **{worst_subject[0]}**å­¦ç§‘æ­£ç¡®ç‡ä»…{worst_subject[1]*100:.1f}%ï¼Œéœ€è¦é‡ç‚¹æ”¹è¿›\n"
                response += f"- åŠ å¼ºå­¦ç§‘æ•™ç ”ï¼Œä¼˜åŒ–æ•™å­¦å†…å®¹å’Œæ–¹æ³•\n\n"
        
        response += f"**4. æ•°æ®é©±åŠ¨å†³ç­–**\n"
        response += f"- å»ºç«‹å‘¨æŠ¥åˆ†ææœºåˆ¶ï¼ŒæŒç»­ç›‘æ§å…³é”®æŒ‡æ ‡\n"
        response += f"- åŸºäºæ•°æ®è°ƒæ•´æ•™å­¦ç­–ç•¥ï¼Œå®ç°ç²¾å‡†æ•™å­¦\n"
        
        return response
    
    def _generate_class_analysis(self, best_class, focus_class):
        """ç”Ÿæˆç­çº§åˆ†æ"""
        response = f"## ğŸ« ç­çº§è¡¨ç°åˆ†æ\n\n"
        
        response += f"### ğŸ† æ ‡æ†ç­çº§\n"
        response += f"**{best_class['name']}** ç»¼åˆè¡¨ç°æœ€ä½³ï¼š\n"
        response += f"- å‡ºå‹¤ç‡: {best_class['attendance_rate']*100:.1f}%\n"
        response += f"- é¢˜ç›®æ­£ç¡®ç‡: {best_class['correctness_rate']*100:.1f}%\n"
        response += f"- æ¶‰åŠå­¦ç§‘: {best_class['subjects']}\n\n"
        
        if focus_class['name']:
            response += f"### âš ï¸ é‡ç‚¹å…³æ³¨ç­çº§\n"
            response += f"**{focus_class['name']}** éœ€è¦ç‰¹åˆ«å…³æ³¨ï¼š\n"
            response += f"- å‡ºå‹¤æƒ…å†µè‰¯å¥½: {focus_class['attendance_rate']*100:.1f}%\n"
            response += f"- ä½†å­¦ä¹ æ•ˆæœä¸ä½³: æ­£ç¡®ç‡{focus_class['correctness_rate']*100:.1f}%\n"
            response += f"- æ¶‰åŠå­¦ç§‘: {focus_class['subjects']}\n\n"
        
        response += f"### ç®¡ç†å»ºè®®\n"
        response += f"1. **å·®å¼‚åŒ–æ•™å­¦**: é’ˆå¯¹ä¸åŒç­çº§ç‰¹ç‚¹åˆ¶å®šæ•™å­¦æ–¹æ¡ˆ\n"
        response += f"2. **ç»“å¯¹å¸®æ‰¶**: ç»„ç»‡ä¼˜ç§€ç­çº§ä¸å¾…æå‡ç­çº§ç»“å¯¹\n"
        response += f"3. **å®šæœŸåé¦ˆ**: å»ºç«‹ç­çº§è¡¨ç°åé¦ˆæœºåˆ¶\n"
        
        return response
    
    def _generate_subject_analysis(self, top_subjects):
        """ç”Ÿæˆå­¦ç§‘åˆ†æ"""
        response = f"## ğŸ“š å­¦ç§‘è¡¨ç°åˆ†æ\n\n"
        
        response += f"### è¯¾æ—¶åˆ†å¸ƒ\n"
        for subject in top_subjects:
            response += f"- **{subject['è¯¾æ—¶å­¦ç§‘']}**: {int(subject['æ€»è¯¾æ—¶'])}è¯¾æ—¶ï¼Œæ­£ç¡®ç‡{subject['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']*100:.1f}%ï¼Œæ¶‰åŠ{int(subject['æ¶‰åŠç­çº§æ•°'])}ä¸ªç­çº§\n"
        
        response += f"\n### å­¦ç§‘ç‰¹ç‚¹åˆ†æ\n"
        
        # æ‰¾å‡ºè¡¨ç°æœ€å¥½å’Œæœ€å·®çš„å­¦ç§‘
        if len(top_subjects) >= 2:
            subjects_with_correctness = [(s['è¯¾æ—¶å­¦ç§‘'], s['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']) for s in top_subjects if s['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡'] > 0]
            if subjects_with_correctness:
                best_subject = max(subjects_with_correctness, key=lambda x: x[1])
                worst_subject = min(subjects_with_correctness, key=lambda x: x[1])
                
                response += f"1. **ä¼˜åŠ¿å­¦ç§‘**: {best_subject[0]}ï¼Œæ­£ç¡®ç‡è¾¾{best_subject[1]*100:.1f}%ï¼Œæ•™å­¦æ•ˆæœæ˜¾è‘—\n"
                response += f"2. **å¾…æå‡å­¦ç§‘**: {worst_subject[0]}ï¼Œæ­£ç¡®ç‡ä»…{worst_subject[1]*100:.1f}%ï¼Œéœ€è¦é‡ç‚¹æ”¹è¿›\n"
        
        response += f"\n### å­¦ç§‘å»ºè®¾å»ºè®®\n"
        response += f"1. **ä¼˜åŒ–èµ„æºé…ç½®**: æ ¹æ®å­¦ç§‘éœ€æ±‚åˆç†åˆ†é…æ•™å­¦èµ„æº\n"
        response += f"2. **åŠ å¼ºå­¦ç§‘æ•™ç ”**: å®šæœŸå¼€å±•å­¦ç§‘æ•™ç ”æ´»åŠ¨ï¼Œåˆ†äº«æˆåŠŸç»éªŒ\n"
        response += f"3. **è·¨å­¦ç§‘æ•´åˆ**: ä¿ƒè¿›å­¦ç§‘é—´çš„çŸ¥è¯†èåˆå’Œæ–¹æ³•å€Ÿé‰´\n"
        
        return response
    
    def _generate_trend_analysis(self):
        """ç”Ÿæˆè¶‹åŠ¿åˆ†æ"""
        weekly_trends = self.analysis_results['weekly_trends']
        
        if len(weekly_trends) < 2:
            return "å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æã€‚"
        
        first_week = weekly_trends[0]
        last_week = weekly_trends[-1]
        
        response = f"## ğŸ“ˆ å†å²è¶‹åŠ¿åˆ†æ\n\n"
        response += f"### æ—¶é—´è·¨åº¦\n"
        response += f"- ä» **{first_week['week']}** åˆ° **{last_week['week']}**\n"
        response += f"- å…± **{len(weekly_trends)}** å‘¨æ•°æ®\n\n"
        
        response += f"### å…³é”®æŒ‡æ ‡å˜åŒ–\n"
        
        # è®¡ç®—å˜åŒ–ç™¾åˆ†æ¯”
        hours_change = ((last_week['total_hours'] - first_week['total_hours']) / first_week['total_hours']) * 100
        att_change = ((last_week['attendance_rate'] - first_week['attendance_rate']) / first_week['attendance_rate']) * 100
        corr_change = ((last_week['correctness_rate'] - first_week['correctness_rate']) / first_week['correctness_rate']) * 100
        
        response += f"1. **æ•™å­¦è§„æ¨¡**: {first_week['total_hours']} â†’ {last_week['total_hours']}è¯¾æ—¶ ({'å¢é•¿' if hours_change > 0 else 'å‡å°‘'} {abs(hours_change):.1f}%)\n"
        response += f"2. **å‡ºå‹¤ç¨³å®šæ€§**: {first_week['attendance_rate']*100:.1f}% â†’ {last_week['attendance_rate']*100:.1f}% ({'æå‡' if att_change > 0 else 'ä¸‹é™'} {abs(att_change):.1f}%)\n"
        response += f"3. **å­¦ä¹ æ•ˆæœ**: {first_week['correctness_rate']*100:.1f}% â†’ {last_week['correctness_rate']*100:.1f}% ({'æå‡' if corr_change > 0 else 'ä¸‹é™'} {abs(corr_change):.1f}%)\n\n"
        
        response += f"### è¶‹åŠ¿è§£è¯»\n"
        if hours_change > 0:
            response += f"- âœ… æ•™å­¦è§„æ¨¡æŒç»­æ‰©å¤§ï¼Œè¯´æ˜AIè¯¾å ‚åº”ç”¨é€æ¸æ·±å…¥\n"
        else:
            response += f"- âš ï¸ æ•™å­¦è§„æ¨¡æœ‰æ‰€æ”¶ç¼©ï¼Œéœ€è¦å…³æ³¨è¯¾ç¨‹å®‰æ’\n"
        
        if att_change > 0:
            response += f"- âœ… å‡ºå‹¤ç‡ä¿æŒç¨³å®šæˆ–ç•¥æœ‰æå‡ï¼Œå­¦ç”Ÿå‚ä¸åº¦è‰¯å¥½\n"
        else:
            response += f"- âš ï¸ å‡ºå‹¤ç‡æœ‰æ‰€ä¸‹é™ï¼Œéœ€è¦åŠ å¼ºå­¦ç”Ÿç®¡ç†å’Œè¯¾ç¨‹å¸å¼•åŠ›\n"
        
        if corr_change > 0:
            response += f"- âœ… å­¦ä¹ æ•ˆæœé€æ­¥æå‡ï¼Œæ•™å­¦æ–¹æ³•æœ‰æ•ˆ\n"
        else:
            response += f"- âš ï¸ å­¦ä¹ æ•ˆæœæœ‰å¾…æå‡ï¼Œéœ€è¦ä¼˜åŒ–æ•™å­¦ç­–ç•¥\n"
        
        return response
    
    def _generate_general_response(self, user_query, metrics):
        """ç”Ÿæˆé€šç”¨å“åº”"""
        response = f"## ğŸ¤– AIåˆ†æå“åº”\n\n"
        response += f"åŸºäºæ‚¨çš„é—®é¢˜ã€Œ{user_query}ã€ï¼Œç»“åˆæœ¬å‘¨æ•™å­¦æ•°æ®åˆ†æï¼š\n\n"
        
        response += f"### å½“å‰æ•™å­¦çŠ¶å†µ\n"
        response += f"- **æ•™å­¦è§„æ¨¡**: {metrics['total_hours']}è¯¾æ—¶ï¼Œæ¶‰åŠ{metrics['total_classes']}ä¸ªç­çº§\n"
        response += f"- **å­¦ç”Ÿå‚ä¸**: å¹³å‡å‡ºå‹¤ç‡{metrics['attendance_rate']*100:.1f}%\n"
        response += f"- **å­¦ä¹ æ•ˆæœ**: é¢˜ç›®æ­£ç¡®ç‡{metrics['correctness_rate']*100:.1f}%\n\n"
        
        response += f"### æ ¸å¿ƒå…³æ³¨ç‚¹\n"
        response += f"1. **å­¦ä¹ è´¨é‡æå‡**: å½“å‰æ­£ç¡®ç‡æœ‰è¾ƒå¤§æå‡ç©ºé—´\n"
        response += f"2. **æ•™å­¦å·®å¼‚åŒ–**: ä¸åŒç­çº§å’Œå­¦ç§‘è¡¨ç°å·®å¼‚æ˜æ˜¾\n"
        response += f"3. **æŒç»­æ”¹è¿›**: éœ€è¦åŸºäºæ•°æ®ä¸æ–­ä¼˜åŒ–æ•™å­¦ç­–ç•¥\n\n"
        
        response += f"### å»ºè®®è¿›ä¸€æ­¥åˆ†æ\n"
        response += f"å¦‚éœ€æ›´æ·±å…¥çš„åˆ†æï¼Œæ‚¨å¯ä»¥å°è¯•è¯¢é—®ï¼š\n"
        response += f"- å‡ºå‹¤ç‡è¯¦ç»†åˆ†æ\n"
        response += f"- é¢˜ç›®æ­£ç¡®ç‡æ”¹è¿›å»ºè®®\n"
        response += f"- ç­çº§è¡¨ç°å¯¹æ¯”\n"
        response += f"- å­¦ç§‘æ•™å­¦ä¼˜åŒ–\n"
        response += f"- å†å²è¶‹åŠ¿è§£è¯»\n"
        
        return response

# ä¸»ç¨‹åº
if __name__ == "__main__":
    # è¯»å–åˆ†æç»“æœ
    with open('/home/workspace/analysis_results.json', 'r', encoding='utf-8') as f:
        analysis_results = json.load(f)
    
    # åˆ›å»ºAIæŠ¥å‘Šç”Ÿæˆå™¨
    ai_generator = AIReportGenerator(analysis_results)
    
    # ç”Ÿæˆåˆå§‹æŠ¥å‘Š
    initial_report = ai_generator.generate_initial_report()
    
    # ä¿å­˜åˆå§‹æŠ¥å‘Š
    with open('/home/workspace/initial_report.md', 'w', encoding='utf-8') as f:
        f.write(initial_report)
    
    print("âœ… AIæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print(f"åˆå§‹æŠ¥å‘Šå·²ä¿å­˜åˆ°: /home/workspace/initial_report.md")
    print(f"æŠ¥å‘Šé•¿åº¦: {len(initial_report)} å­—ç¬¦")
    
    # æµ‹è¯•AIæŸ¥è¯¢åŠŸèƒ½
    print("\n=== AIæŸ¥è¯¢æµ‹è¯• ===")
    
    test_queries = [
        "å‡ºå‹¤ç‡åˆ†æ",
        "é¢˜ç›®æ­£ç¡®ç‡æ”¹è¿›å»ºè®®",
        "ç­çº§è¡¨ç°å¯¹æ¯”",
        "æ•™å­¦æ”¹è¿›å»ºè®®"
    ]
    
    for query in test_queries:
        print(f"\næŸ¥è¯¢: {query}")
        response = ai_generator.process_ai_query(query)
        print(f"å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
        print(f"å“åº”æ‘˜è¦: {response[:100]}...")