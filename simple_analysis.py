import pandas as pd
import numpy as np
import json
from datetime import datetime

print("å¼€å§‹åˆ†æè€€è¥„å…¨å‘¨æœŸæ•°æ®...")

# è¯»å–Excelæ–‡ä»¶
try:
    df = pd.read_excel('/home/workspace/attachments/è€€è¥„å…¨å‘¨æœŸ.xlsx')
    print(f"æˆåŠŸè¯»å–æ•°æ®ï¼Œè¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")
except Exception as e:
    print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
    exit(1)

# æ•°æ®æ¸…æ´—
# 1. å¤„ç†å‘¨æ¬¡åˆ—
df['å‘¨'] = pd.to_datetime(df['å‘¨'], errors='coerce')
df = df.dropna(subset=['å‘¨'])  # åˆ é™¤å‘¨æ¬¡ä¸ºNaNçš„è¡Œ

# 2. å¡«å……ç¼ºå¤±å€¼
df = df.fillna(0)

# 3. ç¡®ä¿æ•°å€¼åˆ—çš„ç±»å‹
numeric_cols = ['è¯¾æ—¶æ•°', 'è¯¾æ—¶å¹³å‡å‡ºå‹¤ç‡', 'å¾®è¯¾å®Œæˆç‡', 'é¢˜ç›®æ­£ç¡®ç‡ï¼ˆè‡ªå­¦+å¿«èƒŒï¼‰']
for col in numeric_cols:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
        df[col] = df[col].fillna(0)

print(f"æ•°æ®æ¸…æ´—å®Œæˆï¼Œå‰©ä½™è¡Œæ•°: {len(df)}")

# åˆ†ææœ€æ–°å‘¨æ¬¡
latest_week = df['å‘¨'].max()
print(f"\næœ€æ–°å‘¨æ¬¡: {latest_week.strftime('%Y-%m-%d')}")

# è·å–æœ€æ–°å‘¨æ¬¡æ•°æ®
current_week_data = df[df['å‘¨'] == latest_week].copy()
print(f"æœ€æ–°å‘¨æ¬¡æ•°æ®è¡Œæ•°: {len(current_week_data)}")

# è·å–å‰ä¸€å‘¨æ¬¡æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
previous_weeks = df[df['å‘¨'] < latest_week]
if len(previous_weeks) > 0:
    prev_week = previous_weeks['å‘¨'].max()
    prev_week_data = df[df['å‘¨'] == prev_week].copy()
    print(f"å‰ä¸€å‘¨æ¬¡: {prev_week.strftime('%Y-%m-%d')}, æ•°æ®è¡Œæ•°: {len(prev_week_data)}")
else:
    prev_week = None
    prev_week_data = pd.DataFrame()
    print("æ²¡æœ‰å‰ä¸€å‘¨æ•°æ®")

# è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡å‡½æ•°
def calculate_core_metrics(data):
    """è®¡ç®—æ ¸å¿ƒæ•™å­¦æŒ‡æ ‡"""
    if len(data) == 0:
        return None
    
    metrics = {
        'total_hours': int(data['è¯¾æ—¶æ•°'].sum()),
        'total_classes': data['ç­çº§åç§°'].nunique(),
        'total_subjects': data['è¯¾æ—¶å­¦ç§‘'].nunique(),
        'total_records': len(data)
    }
    
    # è®¡ç®—åŠ æƒå¹³å‡å€¼
    def weighted_avg(value_col):
        total_weight = data['è¯¾æ—¶æ•°'].sum()
        if total_weight == 0:
            return 0
        return (data[value_col] * data['è¯¾æ—¶æ•°']).sum() / total_weight
    
    # æ ¸å¿ƒæŒ‡æ ‡
    core_indicators = {
        'attendance_rate': 'è¯¾æ—¶å¹³å‡å‡ºå‹¤ç‡',
        'micro_completion_rate': 'å¾®è¯¾å®Œæˆç‡',
        'correctness_rate': 'é¢˜ç›®æ­£ç¡®ç‡ï¼ˆè‡ªå­¦+å¿«èƒŒï¼‰'
    }
    
    for key, col in core_indicators.items():
        if col in data.columns:
            metrics[key] = float(weighted_avg(col))
        else:
            metrics[key] = 0.0
    
    return metrics

# è®¡ç®—å½“å‰å‘¨æŒ‡æ ‡
current_metrics = calculate_core_metrics(current_week_data)
print(f"\n=== å½“å‰å‘¨æ ¸å¿ƒæŒ‡æ ‡ ===")
if current_metrics:
    print(f"æ€»è¯¾æ—¶: {current_metrics['total_hours']}")
    print(f"æ¶‰åŠç­çº§: {current_metrics['total_classes']}ä¸ª")
    print(f"æ¶‰åŠå­¦ç§‘: {current_metrics['total_subjects']}é—¨")
    print(f"å¹³å‡å‡ºå‹¤ç‡: {current_metrics['attendance_rate']*100:.2f}%")
    print(f"å¾®è¯¾å®Œæˆç‡: {current_metrics['micro_completion_rate']*100:.2f}%")
    print(f"é¢˜ç›®æ­£ç¡®ç‡: {current_metrics['correctness_rate']*100:.2f}%")

# è®¡ç®—å‰ä¸€å‘¨æŒ‡æ ‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if len(prev_week_data) > 0:
    prev_metrics = calculate_core_metrics(prev_week_data)
    print(f"\n=== å‰ä¸€å‘¨æ ¸å¿ƒæŒ‡æ ‡ ===")
    if prev_metrics:
        print(f"æ€»è¯¾æ—¶: {prev_metrics['total_hours']}")
        print(f"å¹³å‡å‡ºå‹¤ç‡: {prev_metrics['attendance_rate']*100:.2f}%")
        print(f"å¾®è¯¾å®Œæˆç‡: {prev_metrics['micro_completion_rate']*100:.2f}%")
        print(f"é¢˜ç›®æ­£ç¡®ç‡: {prev_metrics['correctness_rate']*100:.2f}%")
        
        # è®¡ç®—å˜åŒ–è¶‹åŠ¿
        print(f"\n=== å‘¨ç¯æ¯”å˜åŒ– ===")
        for key in ['total_hours', 'attendance_rate', 'micro_completion_rate', 'correctness_rate']:
            if key in current_metrics and key in prev_metrics:
                current_val = current_metrics[key]
                prev_val = prev_metrics[key]
                if prev_val != 0:
                    change = ((current_val - prev_val) / prev_val) * 100
                    trend = "â†‘" if change > 0 else "â†“" if change < 0 else "â†’"
                    print(f"{key}: {trend} {abs(change):.1f}%")

# ç­çº§è¡¨ç°åˆ†æ
print(f"\n=== ç­çº§è¡¨ç°åˆ†æ ===")
class_stats = current_week_data.groupby('ç­çº§åç§°').apply(
    lambda x: pd.Series({
        'æ€»è¯¾æ—¶': int(x['è¯¾æ—¶æ•°'].sum()),
        'å¹³å‡å‡ºå‹¤ç‡': (x['è¯¾æ—¶å¹³å‡å‡ºå‹¤ç‡'] * x['è¯¾æ—¶æ•°']).sum() / x['è¯¾æ—¶æ•°'].sum() if x['è¯¾æ—¶æ•°'].sum() > 0 else 0,
        'å¹³å‡å¾®è¯¾å®Œæˆç‡': (x['å¾®è¯¾å®Œæˆç‡'] * x['è¯¾æ—¶æ•°']).sum() / x['è¯¾æ—¶æ•°'].sum() if x['è¯¾æ—¶æ•°'].sum() > 0 else 0,
        'å¹³å‡é¢˜ç›®æ­£ç¡®ç‡': (x['é¢˜ç›®æ­£ç¡®ç‡ï¼ˆè‡ªå­¦+å¿«èƒŒï¼‰'] * x['è¯¾æ—¶æ•°']).sum() / x['è¯¾æ—¶æ•°'].sum() if x['è¯¾æ—¶æ•°'].sum() > 0 else 0,
        'æ¶‰åŠå­¦ç§‘': ', '.join(x['è¯¾æ—¶å­¦ç§‘'].dropna().unique()),
        'è®°å½•æ•°': len(x)
    })
).reset_index()

print(f"åˆ†æç­çº§æ•°é‡: {len(class_stats)}")

# æ‰¾å‡ºæœ€ä½³ç­çº§ï¼ˆç»¼åˆè¡¨ç°ï¼‰
if len(class_stats) > 0:
    class_stats['ç»¼åˆå¾—åˆ†'] = (
        class_stats['å¹³å‡å‡ºå‹¤ç‡'] * 0.3 +
        class_stats['å¹³å‡å¾®è¯¾å®Œæˆç‡'] * 0.3 +
        class_stats['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡'] * 0.4
    )
    
    best_class_idx = class_stats['ç»¼åˆå¾—åˆ†'].idxmax()
    best_class = class_stats.loc[best_class_idx]
    
    print(f"\nğŸ† æœ€ä½³ç­çº§: {best_class['ç­çº§åç§°']}")
    print(f"  ç»¼åˆå¾—åˆ†: {best_class['ç»¼åˆå¾—åˆ†']:.3f}")
    print(f"  æ€»è¯¾æ—¶: {best_class['æ€»è¯¾æ—¶']}")
    print(f"  å¹³å‡å‡ºå‹¤ç‡: {best_class['å¹³å‡å‡ºå‹¤ç‡']*100:.1f}%")
    print(f"  å¹³å‡é¢˜ç›®æ­£ç¡®ç‡: {best_class['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']*100:.1f}%")
    print(f"  æ¶‰åŠå­¦ç§‘: {best_class['æ¶‰åŠå­¦ç§‘']}")

# æ‰¾å‡ºéœ€è¦å…³æ³¨çš„ç­çº§ï¼ˆå‡ºå‹¤æ­£å¸¸ä½†æ­£ç¡®ç‡ä½ï¼‰
if current_metrics and len(class_stats) > 0:
    focus_classes = class_stats[
        (class_stats['å¹³å‡å‡ºå‹¤ç‡'] > current_metrics['attendance_rate']) & 
        (class_stats['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡'] < current_metrics['correctness_rate'])
    ]
    
    if len(focus_classes) > 0:
        focus_class = focus_classes.iloc[0]
        print(f"\nâš ï¸ é‡ç‚¹å…³æ³¨ç­çº§: {focus_class['ç­çº§åç§°']}")
        print(f"  å‡ºå‹¤ç‡: {focus_class['å¹³å‡å‡ºå‹¤ç‡']*100:.1f}% (é«˜äºå¹³å‡ {current_metrics['attendance_rate']*100:.1f}%)")
        print(f"  é¢˜ç›®æ­£ç¡®ç‡: {focus_class['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']*100:.1f}% (ä½äºå¹³å‡ {current_metrics['correctness_rate']*100:.1f}%)")
        print(f"  æ¶‰åŠå­¦ç§‘: {focus_class['æ¶‰åŠå­¦ç§‘']}")

# å­¦ç§‘åˆ†æ
print(f"\n=== å­¦ç§‘è¡¨ç°åˆ†æ ===")
subject_stats = current_week_data.groupby('è¯¾æ—¶å­¦ç§‘').apply(
    lambda x: pd.Series({
        'æ€»è¯¾æ—¶': int(x['è¯¾æ—¶æ•°'].sum()),
        'å¹³å‡å‡ºå‹¤ç‡': (x['è¯¾æ—¶å¹³å‡å‡ºå‹¤ç‡'] * x['è¯¾æ—¶æ•°']).sum() / x['è¯¾æ—¶æ•°'].sum() if x['è¯¾æ—¶æ•°'].sum() > 0 else 0,
        'å¹³å‡é¢˜ç›®æ­£ç¡®ç‡': (x['é¢˜ç›®æ­£ç¡®ç‡ï¼ˆè‡ªå­¦+å¿«èƒŒï¼‰'] * x['è¯¾æ—¶æ•°']).sum() / x['è¯¾æ—¶æ•°'].sum() if x['è¯¾æ—¶æ•°'].sum() > 0 else 0,
        'æ¶‰åŠç­çº§æ•°': x['ç­çº§åç§°'].nunique(),
        'è®°å½•æ•°': len(x)
    })
).reset_index()

print(f"åˆ†æå­¦ç§‘æ•°é‡: {len(subject_stats)}")

# æ˜¾ç¤ºè¯¾æ—¶æœ€å¤šçš„å­¦ç§‘
if len(subject_stats) > 0:
    top_subjects = subject_stats.sort_values('æ€»è¯¾æ—¶', ascending=False).head(5)
    print(f"\nğŸ“š è¯¾æ—¶æœ€å¤šçš„5ä¸ªå­¦ç§‘:")
    for _, row in top_subjects.iterrows():
        print(f"  {row['è¯¾æ—¶å­¦ç§‘']}: {row['æ€»è¯¾æ—¶']}è¯¾æ—¶, æ­£ç¡®ç‡:{row['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']*100:.1f}%, æ¶‰åŠ{row['æ¶‰åŠç­çº§æ•°']}ä¸ªç­çº§")

# å†å²è¶‹åŠ¿åˆ†æ
print(f"\n=== å†å²è¶‹åŠ¿åˆ†æ ===")
weekly_trends = []
for week in sorted(df['å‘¨'].unique()):
    week_data = df[df['å‘¨'] == week]
    metrics = calculate_core_metrics(week_data)
    if metrics:
        weekly_trends.append({
            'week': week.strftime('%Y-%m-%d'),
            'total_hours': metrics['total_hours'],
            'attendance_rate': metrics['attendance_rate'],
            'correctness_rate': metrics['correctness_rate'],
            'class_count': metrics['total_classes']
        })

print(f"åˆ†æå‘¨æ¬¡æ•°: {len(weekly_trends)}")

if len(weekly_trends) >= 2:
    first_week = weekly_trends[0]
    last_week = weekly_trends[-1]
    
    print(f"\nğŸ“ˆ æ•´ä½“è¶‹åŠ¿å¯¹æ¯”:")
    print(f"  ä» {first_week['week']} åˆ° {last_week['week']}")
    print(f"  æ€»è¯¾æ—¶: {first_week['total_hours']} â†’ {last_week['total_hours']}")
    print(f"  å‡ºå‹¤ç‡: {first_week['attendance_rate']*100:.1f}% â†’ {last_week['attendance_rate']*100:.1f}%")
    print(f"  é¢˜ç›®æ­£ç¡®ç‡: {first_week['correctness_rate']*100:.1f}% â†’ {last_week['correctness_rate']*100:.1f}%")

# ä¿å­˜åˆ†æç»“æœ
analysis_results = {
    'file_info': {
        'file_name': 'è€€è¥„å…¨å‘¨æœŸ.xlsx',
        'total_records': len(df),
        'date_range': {
            'start': df['å‘¨'].min().strftime('%Y-%m-%d'),
            'end': df['å‘¨'].max().strftime('%Y-%m-%d')
        }
    },
    'current_week': {
        'date': latest_week.strftime('%Y-%m-%d'),
        'metrics': current_metrics,
        'class_stats_count': len(class_stats) if 'class_stats' in locals() else 0,
        'subject_stats_count': len(subject_stats) if 'subject_stats' in locals() else 0
    },
    'best_class': {
        'name': best_class['ç­çº§åç§°'] if 'best_class' in locals() else None,
        'hours': int(best_class['æ€»è¯¾æ—¶']) if 'best_class' in locals() else 0,
        'attendance_rate': float(best_class['å¹³å‡å‡ºå‹¤ç‡']) if 'best_class' in locals() else 0,
        'correctness_rate': float(best_class['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']) if 'best_class' in locals() else 0,
        'subjects': best_class['æ¶‰åŠå­¦ç§‘'] if 'best_class' in locals() else ''
    },
    'focus_class': {
        'name': focus_class['ç­çº§åç§°'] if 'focus_class' in locals() else None,
        'attendance_rate': float(focus_class['å¹³å‡å‡ºå‹¤ç‡']) if 'focus_class' in locals() else 0,
        'correctness_rate': float(focus_class['å¹³å‡é¢˜ç›®æ­£ç¡®ç‡']) if 'focus_class' in locals() else 0,
        'subjects': focus_class['æ¶‰åŠå­¦ç§‘'] if 'focus_class' in locals() else ''
    },
    'top_subjects': top_subjects[['è¯¾æ—¶å­¦ç§‘', 'æ€»è¯¾æ—¶', 'å¹³å‡é¢˜ç›®æ­£ç¡®ç‡', 'æ¶‰åŠç­çº§æ•°']].to_dict('records') if 'top_subjects' in locals() and len(top_subjects) > 0 else [],
    'weekly_trends': weekly_trends,
    'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
}

# ä¿å­˜åˆ°JSONæ–‡ä»¶
output_file = '/home/workspace/analysis_results.json'
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(analysis_results, f, ensure_ascii=False, indent=2, default=str)

print(f"\nâœ… åˆ†æå®Œæˆ!")
print(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
print(f"æ€»åˆ†æè®°å½•: {len(df)}æ¡")
print(f"æ¶‰åŠå‘¨æ¬¡: {len(weekly_trends)}å‘¨")
print(f"æ¶‰åŠç­çº§: {df['ç­çº§åç§°'].nunique()}ä¸ª")
print(f"æ¶‰åŠå­¦ç§‘: {df['è¯¾æ—¶å­¦ç§‘'].nunique()}é—¨")